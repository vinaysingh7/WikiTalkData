{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Talk Data - Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an introduction to working with the various data sets in [Wikipedia\n",
    "Talk](https://figshare.com/projects/Wikipedia_Talk/16731) project on Figshare. The release includes:\n",
    "\n",
    "1. a large historical corpus of discussion comments on Wikipedia talk pages\n",
    "2. a sample of over 100k comments with human labels for whether the comment contains a personal attack\n",
    "3. a sample of over 100k comments with human labels for whether the comment has aggressive tone\n",
    "\n",
    "Please refer to our [wiki](https://meta.wikimedia.org/wiki/Research:Detox/Data_Release) for documentation of the schema of each data set and our [research paper](https://arxiv.org/abs/1610.08914) for documentation on the data collection and modeling methodology. \n",
    "\n",
    "In this notebook we show how to build a simple classifier for detecting personal attacks and apply the classifier to a random sample of the comment corpus to see whether discussions on user pages have more personal attacks than discussion on article pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a classifier for personal attacks\n",
    "In this section we will train a simple bag-of-words classifier for personal attacks using the [Wikipedia Talk Labels: Personal Attacks]() data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Please include .tsv files in local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annoatators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @Data Cleaning\n",
    "\n",
    "This is done by adding all unwanted words in punct set and then iterating over data to remove all the words, by replacing them with space.\n",
    "\n",
    "Then all the unwanted space is merged back to 1 space character.\n",
    "\n",
    "\n",
    "I tried to remove stop words as well from the data but it did not make much difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = set(punctuation)\n",
    "# print ('.' in punct)\n",
    "punct.remove(\".\")\n",
    "# print (punct)\n",
    "punct = str(punct)\n",
    "\n",
    "\n",
    "words = [\"NEWLINE_TOKEN\", \"TAB_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['comment'] = comments['comment'].apply(lambda line : ''.join([line.replace(w, ' ') for w in words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['comment'] = comments['comment'].apply(lambda line : ''.join([' ' if c in punct else c for c in line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['comment'] = comments['comment'].apply(lambda line : ' '.join(line.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### @Features\n",
    "Dropped column year and split from final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>This is not creative . Those are the dictionar...</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>the term standard model is itself less NPOV th...</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>True or false the situation as of March 2002 w...</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next maybe you could work on being less condes...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation. This page ...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102817</th>\n",
       "      <td>Important note for all sysops There is a bug i...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103624</th>\n",
       "      <td>I removed the following All names of early Pol...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111032</th>\n",
       "      <td>If you ever claimed in a Judaic studies progra...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120283</th>\n",
       "      <td>My apologies I m English I watch cricket I kno...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128532</th>\n",
       "      <td>Someone wrote More recognizable perhaps is a t...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133562</th>\n",
       "      <td>Correct. Full biographical details will put do...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138117</th>\n",
       "      <td>Care should be taken to distinguish when and i...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155243</th>\n",
       "      <td>If I may butt in I ve spent the last 1 4 hour ...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177310</th>\n",
       "      <td>On my you will find the apology that I owe you...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192579</th>\n",
       "      <td>I fail to see the distinction. Who better than...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201190</th>\n",
       "      <td>gets far more tendentious yet. gets far more t...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208009</th>\n",
       "      <td>As a person who has done some of this activity...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249432</th>\n",
       "      <td>It s great that we ve found a new source of fr...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252031</th>\n",
       "      <td>No I really haven t heard of either one at lea...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268558</th>\n",
       "      <td>I d like the concepts of microevolution and ma...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276906</th>\n",
       "      <td>I agree the first one is simply wrong and the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286174</th>\n",
       "      <td>Yep that s Twin cities from which this article...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290598</th>\n",
       "      <td>That s another relevant empirical question if ...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294124</th>\n",
       "      <td>This sounds right. Historians speak of these p...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297866</th>\n",
       "      <td>Ummm. The article uses imperial measurements n...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317177</th>\n",
       "      <td>See I was right See I was right NEWLINE TOKENN...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336654</th>\n",
       "      <td>I have checked the licenses and it is public d...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344567</th>\n",
       "      <td>Changed Macedonia link to Macedon ancients did...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356383</th>\n",
       "      <td>Incidentally re naming conventions the only co...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358984</th>\n",
       "      <td>I removed from scratch . In addition to your r...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699646005</th>\n",
       "      <td>Don t keep changing my page I made please. You...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699659494</th>\n",
       "      <td>im soory since when is google images not allow...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699660419</th>\n",
       "      <td>what ever you fuggin fag Question how did you ...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699661020</th>\n",
       "      <td>Nice try but no cigar........idiot Then explai...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699661834</th>\n",
       "      <td>kys style background color fdffe7 border 1px s...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699663770</th>\n",
       "      <td>hi Drmies My name s Little Cletus I m just her...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699664687</th>\n",
       "      <td>shut up mind your own business and go fuck som...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699667660</th>\n",
       "      <td>This talk page is actually a better place to d...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699683891</th>\n",
       "      <td>defunct The article sources a claim that WOJAC...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699698850</th>\n",
       "      <td>Yeah I realized I created a duplicate ID. Sorr...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699702006</th>\n",
       "      <td>There s some weaseling and pov pushing in the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699703322</th>\n",
       "      <td>Yeah and in the earlier sentence I d reword fe...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699715740</th>\n",
       "      <td>Again WP NOTAFORUM and there s usually a good ...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699728036</th>\n",
       "      <td>Those Were the Days Those Were the Days</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699730832</th>\n",
       "      <td>Japanese Scene The largely neoclassical Japane...</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699732149</th>\n",
       "      <td>I am sorry I was only apologizing for if my in...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699741197</th>\n",
       "      <td>Jim1138 Hi. How did you get involved in this b...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699753082</th>\n",
       "      <td>Why oh why... You removed the trolls ANI secti...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699755057</th>\n",
       "      <td>Daily Beast Article I m removing the source th...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699756053</th>\n",
       "      <td>The lead also lacks proper citation and source...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699756185</th>\n",
       "      <td>The lead itself is original research. Where is...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699780538</th>\n",
       "      <td>Well done thanks NEWLINE TOKEN Well done thanks</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699813325</th>\n",
       "      <td>I m talking about you making unjustified major...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699820699</th>\n",
       "      <td>Yes from the word Guci or Puci meaning flash o...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699822249</th>\n",
       "      <td>Comment . Gentlemen this article provides an i...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699848324</th>\n",
       "      <td>These sources don t exactly exude a sense of i...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699851288</th>\n",
       "      <td>The Institute for Historical Review is a peer ...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699857133</th>\n",
       "      <td>The way you re trying to describe it in this a...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699891012</th>\n",
       "      <td>Warning There is clearly a protectionist regim...</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699897151</th>\n",
       "      <td>Alternate option Is there perhaps enough newsw...</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     comment  logged_in  \\\n",
       "rev_id                                                                    \n",
       "37675      This is not creative . Those are the dictionar...      False   \n",
       "44816      the term standard model is itself less NPOV th...      False   \n",
       "49851      True or false the situation as of March 2002 w...      False   \n",
       "89320      Next maybe you could work on being less condes...       True   \n",
       "93890      This page will need disambiguation. This page ...       True   \n",
       "102817     Important note for all sysops There is a bug i...       True   \n",
       "103624     I removed the following All names of early Pol...       True   \n",
       "111032     If you ever claimed in a Judaic studies progra...       True   \n",
       "120283     My apologies I m English I watch cricket I kno...       True   \n",
       "128532     Someone wrote More recognizable perhaps is a t...       True   \n",
       "133562     Correct. Full biographical details will put do...       True   \n",
       "138117     Care should be taken to distinguish when and i...       True   \n",
       "155243     If I may butt in I ve spent the last 1 4 hour ...       True   \n",
       "177310     On my you will find the apology that I owe you...       True   \n",
       "192579     I fail to see the distinction. Who better than...       True   \n",
       "201190     gets far more tendentious yet. gets far more t...       True   \n",
       "208009     As a person who has done some of this activity...       True   \n",
       "249432     It s great that we ve found a new source of fr...       True   \n",
       "252031     No I really haven t heard of either one at lea...       True   \n",
       "268558     I d like the concepts of microevolution and ma...       True   \n",
       "276906     I agree the first one is simply wrong and the ...       True   \n",
       "286174     Yep that s Twin cities from which this article...       True   \n",
       "290598     That s another relevant empirical question if ...       True   \n",
       "294124     This sounds right. Historians speak of these p...       True   \n",
       "297866     Ummm. The article uses imperial measurements n...       True   \n",
       "317177     See I was right See I was right NEWLINE TOKENN...       True   \n",
       "336654     I have checked the licenses and it is public d...       True   \n",
       "344567     Changed Macedonia link to Macedon ancients did...       True   \n",
       "356383     Incidentally re naming conventions the only co...       True   \n",
       "358984     I removed from scratch . In addition to your r...       True   \n",
       "...                                                      ...        ...   \n",
       "699646005  Don t keep changing my page I made please. You...       True   \n",
       "699659494  im soory since when is google images not allow...       True   \n",
       "699660419  what ever you fuggin fag Question how did you ...       True   \n",
       "699661020  Nice try but no cigar........idiot Then explai...       True   \n",
       "699661834  kys style background color fdffe7 border 1px s...       True   \n",
       "699663770  hi Drmies My name s Little Cletus I m just her...       True   \n",
       "699664687  shut up mind your own business and go fuck som...       True   \n",
       "699667660  This talk page is actually a better place to d...       True   \n",
       "699683891  defunct The article sources a claim that WOJAC...       True   \n",
       "699698850  Yeah I realized I created a duplicate ID. Sorr...       True   \n",
       "699702006  There s some weaseling and pov pushing in the ...       True   \n",
       "699703322  Yeah and in the earlier sentence I d reword fe...       True   \n",
       "699715740  Again WP NOTAFORUM and there s usually a good ...       True   \n",
       "699728036            Those Were the Days Those Were the Days       True   \n",
       "699730832  Japanese Scene The largely neoclassical Japane...      False   \n",
       "699732149  I am sorry I was only apologizing for if my in...       True   \n",
       "699741197  Jim1138 Hi. How did you get involved in this b...       True   \n",
       "699753082  Why oh why... You removed the trolls ANI secti...       True   \n",
       "699755057  Daily Beast Article I m removing the source th...       True   \n",
       "699756053  The lead also lacks proper citation and source...       True   \n",
       "699756185  The lead itself is original research. Where is...       True   \n",
       "699780538    Well done thanks NEWLINE TOKEN Well done thanks      False   \n",
       "699813325  I m talking about you making unjustified major...       True   \n",
       "699820699  Yes from the word Guci or Puci meaning flash o...       True   \n",
       "699822249  Comment . Gentlemen this article provides an i...       True   \n",
       "699848324  These sources don t exactly exude a sense of i...       True   \n",
       "699851288  The Institute for Historical Review is a peer ...       True   \n",
       "699857133  The way you re trying to describe it in this a...       True   \n",
       "699891012  Warning There is clearly a protectionist regim...       True   \n",
       "699897151  Alternate option Is there perhaps enough newsw...       True   \n",
       "\n",
       "                ns   sample  attack  \n",
       "rev_id                               \n",
       "37675      article   random   False  \n",
       "44816      article   random   False  \n",
       "49851      article   random   False  \n",
       "89320      article   random   False  \n",
       "93890      article   random   False  \n",
       "102817        user   random   False  \n",
       "103624     article   random   False  \n",
       "111032     article   random   False  \n",
       "120283     article   random   False  \n",
       "128532     article   random   False  \n",
       "133562     article   random   False  \n",
       "138117     article   random   False  \n",
       "155243        user   random   False  \n",
       "177310        user   random   False  \n",
       "192579     article   random   False  \n",
       "201190     article   random   False  \n",
       "208009        user   random   False  \n",
       "249432     article   random   False  \n",
       "252031     article   random   False  \n",
       "268558     article   random   False  \n",
       "276906     article   random   False  \n",
       "286174     article   random   False  \n",
       "290598     article   random   False  \n",
       "294124     article   random   False  \n",
       "297866     article   random   False  \n",
       "317177     article   random   False  \n",
       "336654        user   random   False  \n",
       "344567     article   random   False  \n",
       "356383     article   random   False  \n",
       "358984     article   random   False  \n",
       "...            ...      ...     ...  \n",
       "699646005     user  blocked   False  \n",
       "699659494     user  blocked    True  \n",
       "699660419     user  blocked    True  \n",
       "699661020     user  blocked    True  \n",
       "699661834     user  blocked   False  \n",
       "699663770     user  blocked   False  \n",
       "699664687     user  blocked    True  \n",
       "699667660  article  blocked   False  \n",
       "699683891  article  blocked   False  \n",
       "699698850     user  blocked   False  \n",
       "699702006  article  blocked   False  \n",
       "699703322  article  blocked   False  \n",
       "699715740  article  blocked   False  \n",
       "699728036  article   random   False  \n",
       "699730832  article  blocked   False  \n",
       "699732149     user   random   False  \n",
       "699741197     user  blocked   False  \n",
       "699753082     user  blocked   False  \n",
       "699755057  article  blocked   False  \n",
       "699756053  article  blocked   False  \n",
       "699756185  article  blocked   False  \n",
       "699780538     user  blocked   False  \n",
       "699813325  article  blocked   False  \n",
       "699820699     user  blocked   False  \n",
       "699822249  article  blocked   False  \n",
       "699848324  article  blocked   False  \n",
       "699851288  article  blocked   False  \n",
       "699857133  article  blocked   False  \n",
       "699891012     user  blocked   False  \n",
       "699897151  article  blocked   False  \n",
       "\n",
       "[115864 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "train_comments.drop(columns=['year', 'split'])\n",
    "comments.drop(columns=['year', 'split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression (Best Model)\n",
    "\n",
    "This model provided the best ROC_AUC and F1 scores.\n",
    "\n",
    "By tuning Countectorizer, TfidfTransformer and LogisticRegression parameters F1 score increased from around 68.5 to 73.5%.\n",
    "\n",
    "Adding class_weight = \"balanced\" to LogisticRegression had the most effect on scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logs_reg = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=5, max_features = 50000, analyzer='word')),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf = True)),\n",
    "    ('clf', LogisticRegression(class_weight = \"balanced\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logs_reg = clf_logs_reg.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_comments['attack'], clf_logs_reg.predict(test_comments['comment'])).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive= 2295\n",
      "True Negative= 19232\n",
      "False Positive= 1190\n",
      "False Negative= 461\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive=\", tp)\n",
    "print (\"True Negative=\", tn)\n",
    "print (\"False Positive=\", fp)\n",
    "print (\"False Negative=\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "    True Positive= 2295\n",
    "    True Negative= 19232\n",
    "    False Positive= 1190\n",
    "    False Negative= 461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train-Test Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 96.191\n",
      "Precesion: 65.854\n",
      "Recall: 83.273\n",
      "F1: 73.546\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test_comments['attack'], clf_logs_reg.predict_proba(test_comments['comment'])[:, 1])\n",
    "precesion, recall, f1, _ = prf(test_comments['attack'], clf_logs_reg.predict(test_comments['comment']), average='binary')\n",
    "print('Test ROC AUC: %.3f' %(auc*100))\n",
    "print(\"Precesion: %.3f\" %(precesion*100))\n",
    "print(\"Recall: %.3f\" %(recall*100))\n",
    "print(\"F1: %.3f\" %(f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy\n",
    "    Test ROC AUC: 96.191\n",
    "    Precesion:  65.85365853658537\n",
    "    Recall:  83.27285921625544\n",
    "    F1:  73.5459061047909"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf_logs_reg, comments['comment'], comments['attack'], cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92759127 0.91464572 0.92707344 0.9187883  0.91765924 0.92266529\n",
      " 0.92784395 0.93017435 0.92922493 0.92525462]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Score for each fold \n",
    "    [0.92759127 0.91464572 0.92707344 0.9187883  0.91765924 0.92266529\n",
    "     0.92784395 0.93017435 0.92922493 0.92525462]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Accuracy: 0.92 (+/- 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_multi_nb = Pipeline([\n",
    "    ('vect1', CountVectorizer(min_df=5, max_features = 50000, analyzer='word')),\n",
    "    ('tfidf2', TfidfTransformer(norm = 'l2',sublinear_tf = True)),\n",
    "    ('multi_nb', MultinomialNB(fit_prior=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_multi_nb = clf_multi_nb.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_comments['attack'], clf_multi_nb.predict(test_comments['comment'])).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive= 2020\n",
      "True Negative= 19048\n",
      "False Positive= 1374\n",
      "False Negative= 736\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive=\", tp)\n",
    "print (\"True Negative=\", tn)\n",
    "print (\"False Positive=\", fp)\n",
    "print (\"False Negative=\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "    True Positive= 2020\n",
    "    True Negative= 19048\n",
    "    False Positive= 1374\n",
    "    False Negative= 736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 91.425\n",
      "Precesion:  59.51679434295816\n",
      "Recall:  73.29462989840349\n",
      "F1:  65.6910569105691\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test_comments['attack'], clf_multi_nb.predict_proba(test_comments['comment'])[:, 1])\n",
    "precesion, recall, f1, _ = prf(test_comments['attack'], clf_multi_nb.predict(test_comments['comment']), average='binary')\n",
    "\n",
    "print('Test ROC AUC: %.3f' %(auc*100))\n",
    "print(\"Precesion: %.3f\" %(precesion*100))\n",
    "print(\"Recall: %.3f\" %(recall*100))\n",
    "print(\"F1: %.3f\" %(f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy\n",
    "    Test ROC AUC: 91.425\n",
    "    Precesion:  59.51679434295816\n",
    "    Recall:  73.29462989840349\n",
    "    F1:  65.6910569105691\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rand_for = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, analyzer='word')),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf = True)),\n",
    "    ('rand_for', RandomForestClassifier(n_estimators=500)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rand_for = clf_rand_for.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_comments['attack'], clf_rand_for.predict(test_comments['comment'])).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive= 1339\n",
      "True Negative= 20329\n",
      "False Positive= 93\n",
      "False Negative= 1417\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive=\", tp)\n",
    "print (\"True Negative=\", tn)\n",
    "print (\"False Positive=\", fp)\n",
    "print (\"False Negative=\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "    True Positive= 1339\n",
    "    True Negative= 20329\n",
    "    False Positive= 93\n",
    "    False Negative= 1417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 95.482\n",
      "Precesion: 93.506\n",
      "Recall: 48.585\n",
      "F1: 63.945\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test_comments['attack'], clf_rand_for.predict_proba(test_comments['comment'])[:, 1])\n",
    "precesion, recall, f1, _ = prf(test_comments['attack'], clf_rand_for.predict(test_comments['comment']), average='binary')\n",
    "# type(prfscore)\n",
    "print('Test ROC AUC: %.3f' %(auc*100))\n",
    "print(\"Precesion: %.3f\" %(precesion*100))\n",
    "print(\"Recall: %.3f\" %(recall*100))\n",
    "print(\"F1: %.3f\" %(f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy\n",
    "    Test ROC AUC: 95.482\n",
    "    Precesion: 93.506\n",
    "    Recall: 48.585\n",
    "    F1: 63.945\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, analyzer='word', ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf = True)),\n",
    "    ('rand_for', SVC(kernel='linear')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = clf_SVC.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_comments['attack'], clf_SVC.predict(test_comments['comment'])).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive= 1674\n",
      "True Negative= 20235\n",
      "False Positive= 187\n",
      "False Negative= 1082\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive=\", tp)\n",
    "print (\"True Negative=\", tn)\n",
    "print (\"False Positive=\", fp)\n",
    "print (\"False Negative=\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matirx\n",
    "    True Positive= 1674\n",
    "    True Negative= 20235\n",
    "    False Positive= 187\n",
    "    False Negative= 1082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 79.912\n",
      "Precesion:  89.95163890381515\n",
      "Recall:  60.74020319303338\n",
      "F1:  72.51461988304094\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test_comments['attack'], clf_SVC.predict(test_comments['comment']))\n",
    "precesion, recall, f1, _ = prf(test_comments['attack'], clf_SVC.predict(test_comments['comment']), average='binary')\n",
    "# type(prfscore)\n",
    "print('Test ROC AUC: %.3f' %(auc*100))\n",
    "print(\"Precesion: \", (precesion*100))\n",
    "print(\"Recall: \", (recall*100))\n",
    "print(\"F1: \", (f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy\n",
    "    Test ROC AUC: 79.912 vs 88.723(LogisticRegression)\n",
    "    Precesion:  89.95163890381515\n",
    "    Recall:  60.74020319303338\n",
    "    F1:  72.51461988304094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC2 = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, analyzer='word')),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf = True)),\n",
    "    ('rand_for', LinearSVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC2 = clf_SVC2.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_comments['attack'], clf_SVC2.predict(test_comments['comment'])).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive= 1751\n",
      "True Negative= 20131\n",
      "False Positive= 291\n",
      "False Negative= 1005\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive=\", tp)\n",
    "print (\"True Negative=\", tn)\n",
    "print (\"False Positive=\", fp)\n",
    "print (\"False Negative=\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "    True Positive= 1751\n",
    "    True Negative= 20131\n",
    "    False Positive= 291\n",
    "    False Negative= 1005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 81.055\n",
      "Precesion: 85.749\n",
      "Recall: 63.534\n",
      "F1: 72.989\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test_comments['attack'], clf_SVC2.predict(test_comments['comment']))\n",
    "precesion, recall, f1, _ = prf(test_comments['attack'], clf_SVC2.predict(test_comments['comment']), average='binary')\n",
    "\n",
    "print('Test ROC AUC: %.3f' %(auc*100))\n",
    "print(\"Precesion: %.3f\" %(precesion*100))\n",
    "print(\"Recall: %.3f\" %(recall*100))\n",
    "print(\"F1: %.3f\" %(f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy\n",
    "\n",
    "    Test ROC AUC: 81.055  vs 88.723(LogisticRegression)\n",
    "    Precesion: 85.749\n",
    "    Recall: 63.534\n",
    "    F1: 72.989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_MLP = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, analyzer='word', ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2',sublinear_tf = True)),\n",
    "    ('rand_for', MLPClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_MLP = clf_MLP.fit(train_comments['comment'], train_comments['attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_comments['attack'], clf_MLP.predict(test_comments['comment'])).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive= 1789\n",
      "True Negative= 19771\n",
      "False Positive= 651\n",
      "False Negative= 967\n"
     ]
    }
   ],
   "source": [
    "print (\"True Positive=\", tp)\n",
    "print (\"True Negative=\", tn)\n",
    "print (\"False Positive=\", fp)\n",
    "print (\"False Negative=\", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "    True Positive= 1789\n",
    "    True Negative= 19771\n",
    "    False Positive= 651\n",
    "    False Negative= 967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(test_comments['attack'], clf_MLP.predict_proba(test_comments['comment'])[:, 1])\n",
    "precesion, recall, f1, _ = prf(test_comments['attack'], clf_MLP.predict(test_comments['comment']), average='binary')\n",
    "\n",
    "print('Test ROC AUC: %.3f' %(auc*100))\n",
    "print(\"Precesion: \", (precesion*100))\n",
    "print(\"Recall: \", (recall*100))\n",
    "print(\"F1: \", (f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output\n",
    "    Test ROC AUC: 91.655\n",
    "    Precesion:  71.08533554266778\n",
    "    Recall:  62.264150943396224\n",
    "    F1:  66.38297872340425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clf_logs_reg.predict(test_comments['comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf_logs_reg.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.any(a == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf_logs_reg.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
